{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import keras\n",
    "import glob\n",
    "import shutil\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "#print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#dataset parameters\n",
    "MODE = 'folder'\n",
    "DATASET_PATH = '/Users/user_name/Desktop/New folder/Study/flower_photos'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image parameters\n",
    "N_CLASSES = 5\n",
    "IMG_SHAPE = 150\n",
    "CHANNELS = 3\n",
    "BATCH_SIZE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_images(dataset_path):\n",
    "    imagepaths, labels = list(), list()\n",
    "    try :\n",
    "        classes = sorted(os.walk(dataset_path).__next__()[1])\n",
    "    except Exception:\n",
    "        classes = sorted(os.walk(dataset_path).__next__()[1])\n",
    "    for c in classes:\n",
    "        labels.append(c)\n",
    "        c_dir = os.path.join(dataset_path,c)\n",
    "        images = glob.glob(c_dir + '/*.jpg')\n",
    "        #print(\"{}: {} Images\".format(cl, len(images)))\n",
    "        train, val = images[:round(len(images)*0.8)], images[round(len(images)*0.8):]\n",
    "            \n",
    "        for t in train:\n",
    "            if not os.path.exists(os.path.join(dataset_path, 'train', c)):\n",
    "                os.makedirs(os.path.join(dataset_path, 'train', c))\n",
    "            shutil.move(t, os.path.join(dataset_path, 'train', c))\n",
    "\n",
    "        for v in val:\n",
    "            if not os.path.exists(os.path.join(dataset_path, 'val', c)):\n",
    "                os.makedirs(os.path.join(dataset_path, 'val', c))\n",
    "            shutil.move(v, os.path.join(dataset_path, 'val', c))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the dataset - two modes, file or folder\n",
    "def read_images(dataset_path, mode, batch_size):\n",
    "    \n",
    "    imagepaths, labels = list(), list()\n",
    "    if mode == 'file':\n",
    "        with open(dataset_path) as f:\n",
    "            data = f.read().splitlines()\n",
    "        for d in data:\n",
    "            imagepaths.append(d.split(' ')[0])\n",
    "            labels.append(d.split(' ')[1])\n",
    "    elif mode == 'folder':\n",
    "        label=0\n",
    "        try :\n",
    "            classes = sorted(os.walk(dataset_path).__next__()[1])\n",
    "        except Exception:\n",
    "            classes = sorted(os.walk(dataset_path).__next__()[1])\n",
    "        for c in classes:\n",
    "            c_dir = os.path.join(dataset_path,c)\n",
    "            try:\n",
    "                walk = os.walk(c_dir).__next__()\n",
    "            except:\n",
    "                walk = os.walk(c_dir).__next__()\n",
    "            for sample in walk[2]:\n",
    "                if sample.endswith('.jpg') or sample.endswith('.jpeg'):\n",
    "                    imagepaths.append(os.path.join(c_dir,sample))\n",
    "                    #labels.append(label)\n",
    "            #label = label+1\n",
    "    else:\n",
    "        raise Exception(\"Unknown mode\")\n",
    "        \n",
    "    \n",
    "    #converting to tensor\n",
    "    imagepaths = tf.convert_to_tensor(imagepaths, dtype=tf.string)\n",
    "    #labels = tf.convert_to_tensor(label, dtype=tf.string)\n",
    "    \"\"\"\n",
    "    image, label = tf.train.slice_input_producer([imagepaths, labels], shuffle=True)\n",
    "    \n",
    "    #reading images in tf\n",
    "    image = tf.read_file(image)\n",
    "    image = tf.image.decode_jpeg(image, channels = CHANNELS)\n",
    "    image = tf.image.resize_images(image,IMG_SHAPE)\n",
    "    X, Y = tf.train.batch([image, label], batch_size=BATCH_SIZE,)\n",
    "    \"\"\"\n",
    "    return imagepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join(DATASET_PATH,'train')\n",
    "val_dir = os.path.join(DATASET_PATH,'val')\n",
    "group_images(DATASET_PATH)\n",
    "#X = read_images(train_dir,'folder',150)\n",
    "classes = ['roses', 'daisy', 'dandelion', 'sunflowers', 'tulips']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_daisy_dir = os.path.join(train_dir, 'daisy')  # directory with our training cat pictures\n",
    "train_dandelion_dir = os.path.join(train_dir, 'dandelion')  # directory with our training dog pictures\n",
    "train_roses_dir = os.path.join(train_dir, 'roses')  # directory with our training cat pictures\n",
    "train_sunflowers_dir = os.path.join(train_dir, 'sunflowers')  # directory with our training dog pictures\n",
    "train_tulips_dir = os.path.join(train_dir, 'tulips')  # directory with our training cat pictures\n",
    "\n",
    "val_daisy_dir = os.path.join(val_dir, 'daisy')  # directory with our validation cat pictures\n",
    "val_dandelion_dir = os.path.join(val_dir, 'dandelion')  # directory with our validation dog pictures\n",
    "val_roses_dir = os.path.join(val_dir, 'roses')  # directory with our validation dog pictures\n",
    "val_sunflowers_dir = os.path.join(val_dir, 'sunflowers')  # directory with our validation dog pictures\n",
    "val_tulips_dir = os.path.join(val_dir, 'tulips')  # directory with our validation dog pictures\n",
    "\n",
    "total_train = len(os.listdir(train_daisy_dir)) +len(os.listdir(train_dandelion_dir)) +len(os.listdir(train_roses_dir)) +len(os.listdir(train_sunflowers_dir)) +len(os.listdir(train_tulips_dir))\n",
    "\n",
    "total_val = len(os.listdir(val_daisy_dir))+len(os.listdir(val_dandelion_dir))+len(os.listdir(val_roses_dir))+len(os.listdir(val_sunflowers_dir))+len(os.listdir(val_tulips_dir))\n",
    "\n",
    "print (total_train,'\\t', total_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_gen_train = ImageDataGenerator(rescale=1./255,\n",
    "                                     rotation_range=45,\n",
    "                                     width_shift_range=0.2,\n",
    "                                     height_shift_range=0.2,\n",
    "                                     shear_range=0.2,\n",
    "                                     zoom_range=0.2,\n",
    "                                     horizontal_flip=True,\n",
    "                                    )\n",
    "train_data_gen = image_gen_train.flow_from_directory(batch_size=BATCH_SIZE,\n",
    "                                                     directory=train_dir,\n",
    "                                                     shuffle=True,\n",
    "                                                     target_size=(IMG_SHAPE,IMG_SHAPE), \n",
    "                                                     class_mode='sparse'\n",
    "                                                    )\n",
    "\n",
    "image_gen_val = ImageDataGenerator(rescale=1./255)\n",
    "val_data_gen = image_gen_val.flow_from_directory(batch_size=BATCH_SIZE,\n",
    "                                                 directory=val_dir,\n",
    "                                                 target_size=(IMG_SHAPE,IMG_SHAPE),\n",
    "                                                 class_mode='sparse'\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will plot images in the form of a grid with 1 row and 5 columns where images are placed in each column.\n",
    "def plotImages(images_arr):\n",
    "    fig, axes = plt.subplots(1, 5, figsize=(20,20))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in zip( images_arr, axes):\n",
    "        ax.imshow(img)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "augmented_images = [train_data_gen[0][0][0] for i in range(5)]\n",
    "plotImages(augmented_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(16, 3, padding='same', activation ='relu', input_shape=(IMG_SHAPE,IMG_SHAPE,CHANNELS)),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(32, 3, padding='same', activation ='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(64, 3, padding='same', activation ='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "    \n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512,activation='relu'),\n",
    "    \n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(5,activation = 'softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'sparse_categorical_crossentropy',\n",
    "             optimizer = 'adam',\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs= 30\n",
    "history = model.fit_generator(\n",
    "    train_data_gen,\n",
    "    steps_per_epoch=int(np.ceil(train_data_gen.n / float(BATCH_SIZE))),\n",
    "    epochs=epochs,\n",
    "    validation_data=val_data_gen,\n",
    "    validation_steps=int(np.ceil(val_data_gen.n / float(BATCH_SIZE)))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
